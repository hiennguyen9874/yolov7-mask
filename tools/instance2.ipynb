{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from detectron2.layers import paste_masks_in_image\n",
        "from detectron2.modeling.poolers import ROIPooler\n",
        "from detectron2.structures import Boxes\n",
        "from detectron2.utils.memory import retry_if_cuda_oom\n",
        "from torchvision import transforms\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import (\n",
        "    non_max_suppression_mask_conf,\n",
        "    non_max_suppression,\n",
        "    non_max_suppression_att,\n",
        "    merge_bases,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "with open('data/hyp.scratch.mask.yaml') as f:\n",
        "    hyp = yaml.load(f, Loader=yaml.FullLoader)\n",
        "weigths = torch.load('./weights/yolov7-mask.pt')\n",
        "model = weigths['model']\n",
        "model = model.half().to(device)\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread(\"./inference/images/bus.jpg\")  # 504x378 image\n",
        "image = letterbox(image, 640, stride=64, auto=True)[0]\n",
        "image_ = image.copy()\n",
        "image = transforms.ToTensor()(image)\n",
        "image = torch.tensor(np.array([image.numpy()]))\n",
        "image = image.to(device)\n",
        "image = image.half()\n",
        "\n",
        "output = model(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inf_out, train_out, attn, mask_iou, bases, sem_output = (\n",
        "    output[\"test\"],\n",
        "    output[\"bbox_and_cls\"],\n",
        "    output[\"attn\"],\n",
        "    output[\"mask_iou\"],\n",
        "    output[\"bases\"],\n",
        "    output[\"sem\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inf_out.shape, attn.shape, bases.shape, sem_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(bases.shape)\n",
        "print(sem_output.shape)\n",
        "bases = torch.cat([bases, sem_output], dim=1)\n",
        "print(bases.shape)\n",
        "nb, _, height, width = image.shape\n",
        "names = model.names\n",
        "\n",
        "pooler_scale = model.pooler_scale\n",
        "\n",
        "pooler = ROIPooler(\n",
        "    output_size=hyp[\"mask_resolution\"],\n",
        "    scales=(pooler_scale,),\n",
        "    sampling_ratio=1,\n",
        "    pooler_type=\"ROIAlignV2\",\n",
        "    canonical_level=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output, output_att = non_max_suppression_att(inf_out, attn, conf_thres=0.25, iou_thres=0.65)\n",
        "output[0].shape, output_att[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox = output[0][:, :4]\n",
        "conf = output[0][:, 4]\n",
        "cls = output[0][:, 5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(bases.shape)\n",
        "print(bbox.shape)\n",
        "\n",
        "pooled_bases = pooler([bases], [Boxes(bbox)])\n",
        "pooled_bases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = output_att[0]\n",
        "print(a.shape)\n",
        "\n",
        "pred_masks = (\n",
        "    merge_bases(pooled_bases, a, hyp[\"attn_resolution\"], hyp[\"num_base\"])\n",
        "    .view(a.shape[0], -1)\n",
        "    .sigmoid()\n",
        ")\n",
        "pred_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_pred_masks = pred_masks.view(-1, hyp[\"mask_resolution\"], hyp[\"mask_resolution\"])\n",
        "print(original_pred_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bboxes = Boxes(bbox)\n",
        "\n",
        "pred_masks = retry_if_cuda_oom(paste_masks_in_image)(\n",
        "    original_pred_masks, bboxes, (height, width), threshold=0.5\n",
        ")\n",
        "pred_masks_np = pred_masks.detach().cpu().numpy()\n",
        "\n",
        "pred_cls = cls.detach().cpu().numpy()\n",
        "pred_conf = conf.detach().cpu().numpy()\n",
        "\n",
        "nimg = image[0].permute(1, 2, 0) * 255\n",
        "nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "nbboxes = bboxes.tensor.detach().cpu().numpy().astype(np.int)\n",
        "pnimg = nimg.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for one_mask, bbox, cls, conf in zip(pred_masks_np, nbboxes, pred_cls, pred_conf):\n",
        "    if conf < 0.25:\n",
        "        continue\n",
        "\n",
        "    color = [np.random.randint(255), np.random.randint(255), np.random.randint(255)]\n",
        "\n",
        "    pnimg[one_mask] = pnimg[one_mask] * 0.5 + np.array(color, dtype=np.uint8) * 0.5\n",
        "    # pnimg = cv2.rectangle(pnimg, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
        "\n",
        "    # label = '%s %.3f' % (names[int(cls)], conf)\n",
        "    # t_size = cv2.getTextSize(label, 0, fontScale=0.5, thickness=1)[0]\n",
        "    # c2 = bbox[0] + t_size[0], bbox[1] - t_size[1] - 3\n",
        "    # pnimg = cv2.rectangle(pnimg, (bbox[0], bbox[1]), c2, color, -1, cv2.LINE_AA)  # filled\n",
        "    # pnimg = cv2.putText(pnimg, label, (bbox[0], bbox[1] - 2), 0, 0.5, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# coco example\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.axis('off')\n",
        "plt.imshow(pnimg)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "c3d49e89c7bd06856639c0fbd6f2f72630e37ea7efd2233aa22e73ef8903e9c1"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
