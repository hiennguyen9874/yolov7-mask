{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sSDOngglBk_O",
        "outputId": "1c0a184f-3287-4284-d8de-d1c6222a5289"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade setuptools pip --user\n",
        "# !pip install --ignore-installed PyYAML\n",
        "# !pip install Pillow\n",
        "\n",
        "# !pip install nvidia-pyindex\n",
        "# !pip install --upgrade nvidia-tensorrt\n",
        "# !pip install pycuda\n",
        "\n",
        "# !pip install protobuf<4.21.3\n",
        "# !pip install onnxruntime-gpu\n",
        "# !pip install onnx>=1.9.0\n",
        "# !pip install onnx-simplifier>=0.3.6 --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ5fNost-gZI",
        "outputId": "d54c4359-07f6-40be-d4dd-2e3cc63387c4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version: {sys.version}, {sys.version_info} \")\n",
        "print(f\"Pytorch version: {torch.__version__} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feCaRUEI-_Os",
        "outputId": "b105660f-3f7a-4674-f570-5deda27a96c8"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfZALjuo-_Md",
        "outputId": "42b96832-4eba-420e-a00d-24abe218242b"
      },
      "outputs": [],
      "source": [
        "!# Download YOLOv7 code\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWlHa1NJ-_Jw",
        "outputId": "70b58de9-c5e3-4a3e-9e7f-93cf2dcfcc3d"
      },
      "outputs": [],
      "source": [
        "!# Download trained weights\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX7u8eqj-_Hi",
        "outputId": "01eb26c8-7689-4fe0-bd03-58158e2428c2"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights ./yolov7-tiny.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wZD-nZXX-_Ez",
        "outputId": "c258429b-5c44-466d-b31f-035a20b960ae"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "Image.open('/content/yolov7/runs/detect/exp/horses.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w4lEAvN16Sm",
        "outputId": "6c85fdcf-b4fe-4135-816e-faf5ab3a2d68"
      },
      "outputs": [],
      "source": [
        "# export temporary ONNX model for TensorRT converter\n",
        "!python export.py --weights ./yolov7-tiny.pt --grid --end2end --simplify --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaHB--k_V8h",
        "outputId": "0535dc9b-b34c-40a7-c002-c87120229d2d"
      },
      "outputs": [],
      "source": [
        "# Download ONNX to TensorRT converter\n",
        "%cd ../\n",
        "!git clone https://github.com/Linaom1214/tensorrt-python.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rH_HHdd_V5P",
        "outputId": "b2f2a9aa-31e7-4985-afc0-beedb3663799"
      },
      "outputs": [],
      "source": [
        "%cd tensorrt-python\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjoHQE2_V2g",
        "outputId": "866626d0-4522-4ecb-8465-a831146fad97"
      },
      "outputs": [],
      "source": [
        "# Export TensorRT-engine model \n",
        "!python export.py -o /content/yolov7/yolov7-tiny.onnx -e ./yolov7-tiny-nms.trt -p fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q101zl7-_aHd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict,namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-DABSAOw4Ri"
      },
      "outputs": [],
      "source": [
        "w = './yolov7-tiny-nms.trt'\n",
        "device = torch.device('cuda:0')\n",
        "img = cv2.imread('/content/yolov7/inference/images/horses.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRqqsjDcmyNj"
      },
      "outputs": [],
      "source": [
        "# Infer TensorRT Engine\n",
        "Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
        "logger = trt.Logger(trt.Logger.INFO)\n",
        "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
        "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
        "    model = runtime.deserialize_cuda_engine(f.read())\n",
        "bindings = OrderedDict()\n",
        "for index in range(model.num_bindings):\n",
        "    name = model.get_binding_name(index)\n",
        "    dtype = trt.nptype(model.get_binding_dtype(index))\n",
        "    shape = tuple(model.get_binding_shape(index))\n",
        "    data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
        "    bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
        "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
        "context = model.create_execution_context()\n",
        "\n",
        "\n",
        "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
        "    # Resize and pad image while meeting stride-multiple constraints\n",
        "    shape = im.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    # Scale ratio (new / old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    # Compute padding\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "\n",
        "    if auto:  # minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "\n",
        "    dw /= 2  # divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return im, r, (dw, dh)\n",
        "\n",
        "def postprocess(boxes,r,dwdh):\n",
        "    dwdh = torch.tensor(dwdh*2).to(boxes.device)\n",
        "    boxes -= dwdh\n",
        "    boxes /= r\n",
        "    return boxes\n",
        "\n",
        "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
        "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
        "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
        "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
        "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
        "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
        "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
        "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
        "         'hair drier', 'toothbrush']\n",
        "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzGt5tP9nJs_",
        "outputId": "b5e4658f-8b25-4926-bf87-dced1f966fff"
      },
      "outputs": [],
      "source": [
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "image = img.copy()\n",
        "image, ratio, dwdh = letterbox(image, auto=False)\n",
        "image = image.transpose((2, 0, 1))\n",
        "image = np.expand_dims(image, 0)\n",
        "image = np.ascontiguousarray(image)\n",
        "\n",
        "im = image.astype(np.float32)\n",
        "im.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "xv8UsDWvn9i4",
        "outputId": "b960358f-8993-4b84-c8c8-d169676a014a"
      },
      "outputs": [],
      "source": [
        "im = torch.from_numpy(im).to(device)\n",
        "im/=255\n",
        "im.shape\n",
        "\n",
        "# warmup for 10 times\n",
        "for _ in range(10):\n",
        "    tmp = torch.randn(1,3,640,640).to(device)\n",
        "    binding_addrs['images'] = int(tmp.data_ptr())\n",
        "    context.execute_v2(list(binding_addrs.values()))\n",
        "\n",
        "start = time.perf_counter()\n",
        "binding_addrs['images'] = int(im.data_ptr())\n",
        "context.execute_v2(list(binding_addrs.values()))\n",
        "print(f'Cost {time.perf_counter()-start} s')\n",
        "\n",
        "nums = bindings['num_dets'].data\n",
        "boxes = bindings['det_boxes'].data\n",
        "scores = bindings['det_scores'].data\n",
        "classes = bindings['det_classes'].data\n",
        "nums.shape,boxes.shape,scores.shape,classes.shape\n",
        "\n",
        "boxes = boxes[0,:nums[0][0]]\n",
        "scores = scores[0,:nums[0][0]]\n",
        "classes = classes[0,:nums[0][0]]\n",
        "\n",
        "for box,score,cl in zip(boxes,scores,classes):\n",
        "    box = postprocess(box,ratio,dwdh).round().int()\n",
        "    name = names[cl]\n",
        "    color = colors[name]\n",
        "    name += ' ' + str(round(float(score),3))\n",
        "    cv2.rectangle(img,box[:2].tolist(),box[2:].tolist(),color,2)\n",
        "    cv2.putText(img,name,(int(box[0]), int(box[1]) - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
        "\n",
        "Image.fromarray(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv7ONNXandTRT.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
